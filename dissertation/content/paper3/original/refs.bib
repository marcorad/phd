@book{waveletsandsubbandcoding,
  title={Wavelets and Subband Coding},
  author={Kovacevic, J. and Vetterli, M.},
  isbn={9780130970800},
  lccn={95005967},
  series={Prentice-Hall signal processing series},
  url={https://books.google.co.za/books?id=4Qt_QgAACAAJ},
  year={1995},
  publisher={Prentice Hall PTR}
}

@article{kymatio,
  author  = {Mathieu Andreux and Tomás Angles and Georgios Exarchakis and Roberto Leonarduzzi and Gaspar Rochette and Louis Thiry and John Zarka and Stéphane Mallat and Joakim Andén and Eugene Belilovsky and Joan Bruna and Vincent Lostanlen and Muawiz Chaudhary and Matthew J. Hirn and Edouard Oyallon and Sixin Zhang and Carmine Cella and Michael Eickenberg},
  title   = {Kymatio: Scattering Transforms in Python},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {60},
  pages   = {1--6},
  url     = {http://jmlr.org/papers/v21/19-047.html}
}

@article{2dscattering,
  title={Invariant scattering convolution networks},
  author={Bruna, Joan and Mallat, St{\'e}phane},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1872--1886},
  year={2013},
  publisher={IEEE}
}

@article{sklearn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@article{medmnist,
    title={MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification},
    author={Yang, Jiancheng and Shi, Rui and Wei, Donglai and Liu, Zequan and Zhao, Lin and Ke, Bilian and Pfister, Hanspeter and Ni, Bingbing},
    journal={Scientific Data},
    volume={10},
    number={1},
    pages={41},
    year={2023},
    publisher={Nature Publishing Group UK London}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{1dscattering1,
  title={Multiscale Scattering for Audio Classification.},
  author={And{\'e}n, Joakim and Mallat, St{\'e}phane},
  booktitle={ISMIR},
  pages={657--662},
  year={2011},
  organization={Miami, Florida}
}

@article{3dscattering,
   abstract = {Recent research has shown that utilizing the spectral-spatial information can improve the performance of hyperspectral image (HSI) classification. Since HSI is a 3-D cube datum, 3-D spatial filtering becomes a simple and effective method for extracting the spectral-spatial information. In this paper, we propose a 3-D scattering wavelet transform, which filters the HSI cube data with a cascade of wavelet decompositions, complex modulus, and local weighted averaging. The scattering feature can adequately capture the spectral-spatial information for classification. In the classification step, a support vector machine based on Gaussian kernel is used as a classifier due to its capability to deal with high-dimensional data. Our method is fully evaluated on four classic HSIs, i.e., Indian Pines, Pavia University, Botswana, and Kennedy Space Center. The classification results show that our method achieves as high as 94.46 \%, 99.30 \%, 97.57 \%, and 95.20 \% accuracies, respectively, when only 5 \% of the total samples per class is labeled.},
   author = {Yuan Yan Tang and Yang Lu and Haoliang Yuan},
   doi = {10.1109/TGRS.2014.2360672},
   issn = {01962892},
   issue = {5},
   journal = {IEEE Transactions on Geoscience and Remote Sensing},
   keywords = {3-D scattering wavelet transform,3-D spatial filtering,Classification,hyperspectral image (HSI),spectral-spatial},
   month = {5},
   pages = {2467-2480},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Hyperspectral image classification based on three-dimensional scattering wavelet transform},
   volume = {53},
   year = {2015},
}

@inproceedings{harmonicscattering,
 author = {Eickenberg, Michael and Exarchakis, Georgios and Hirn, Matthew and Mallat, Stephane},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Solid Harmonic Wavelet Scattering: Predicting Quantum Molecular Energy from Invariant Descriptors of 3D  Electronic Densities},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/72b386224056bf940cd5b01341f65e9d-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{jointtfscattering1,
   abstract = {We introduce the joint time-frequency scattering transform, a time shift invariant descriptor of time-frequency structure for audio classification. It is obtained by applying a two-dimensional wavelet transform in time and log-frequency to a time-frequency wavelet scalogram. We show that this descriptor successfully characterizes complex time-frequency phenomena such as time-varying filters and frequency modulated excitations. State-of-the-art results are achieved for signal reconstruction and phone segment classification on the TIMIT dataset.},
   author = {Joakim Andén and Vincent Lostanlen and Stéphane Mallat},
   doi = {10.1109/MLSP.2015.7324385},
   month = {12},
   title = {Joint Time-Frequency Scattering for Audio Classification},
   url = {http://arxiv.org/abs/1512.02125 http://dx.doi.org/10.1109/MLSP.2015.7324385},
   year = {2015},
}

@article{jointtfscattering2,
   abstract = {In time series classification and regression, signals are typically mapped into some intermediate representation used for constructing models. Since the underlying task is often insensitive to time shifts, these representations are required to be time-shift invariant. We introduce the joint time-frequency scattering transform, a time-shift invariant representation which characterizes the multiscale energy distribution of a signal in time and frequency. It is computed through wavelet convolutions and modulus non-linearities and may therefore be implemented as a deep convolutional neural network whose filters are not learned but calculated from wavelets. We consider the progression from mel-spectrograms to time scattering and joint time-frequency scattering transforms, illustrating the relationship between increased discriminability and refinements of convolutional network architectures. The suitability of the joint time-frequency scattering transform for time-shift invariant characterization of time series is demonstrated through applications to chirp signals and audio synthesis experiments. The proposed transform also obtains state-of-the-art results on several audio classification tasks, outperforming time scattering transforms and achieving accuracies comparable to those of fully learned networks.},
   author = {Joakim Andén and Vincent Lostanlen and Stéphane Mallat},
   doi = {10.1109/TSP.2019.2918992},
   month = {7},
   title = {Joint Time-Frequency Scattering},
   url = {http://arxiv.org/abs/1807.08869 http://dx.doi.org/10.1109/TSP.2019.2918992},
   year = {2018},
}


@article{1dscattering2,
  title={Deep scattering spectrum},
  author={And{\'e}n, Joakim and Mallat, St{\'e}phane},
  journal={IEEE Transactions on Signal Processing},
  volume={62},
  number={16},
  pages={4114--4128},
  year={2014},
  publisher={IEEE}
}

@article{groupinvariantscattering,
  title={Group invariant scattering},
  author={Mallat, St{\'e}phane},
  journal={Communications on Pure and Applied Mathematics},
  volume={65},
  number={10},
  pages={1331--1398},
  year={2012},
  publisher={Wiley Online Library}
}

@software{MATLAB,
year = {2022},
author = {{MathWorks Inc.}},
title = {{MATLAB Wavelet Toolbox (R2024a)}},
publisher = {{MathWorks Inc.}},
address = {Natick, Massachusetts, United States},
url = {https://www.mathworks.com/help/wavelet/}
}

@article{learnablewavelettransform,
   abstract = {High-frequency (HF) signals are ubiquitous in the industrial world and are of great use for monitoring of industrial assets. Most deep-learning tools are designed for inputs of fixed and/or very limited size and many successful applications of deep learning to the industrial context use as inputs extracted features, which are a manually and often arduously obtained compact representation of the original signal. In this paper, we propose a fully unsupervised deep-learning framework that is able to extract a meaningful and sparse representation of raw HF signals. We embed in our architecture important properties of the fast discrete wavelet transform (FDWT) such as 1) the cascade algorithm; 2) the conjugate quadrature filter property that links together the wavelet, the scaling, and transposed filter functions; and 3) the coefficient denoising. Using deep learning, we make this architecture fully learnable: Both the wavelet bases and the wavelet coefficient denoising become learnable. To achieve this objective, we propose an activation function that performs a learnable hard thresholding of the wavelet coefficients. With our framework, the denoising FDWT becomes a fully learnable unsupervised tool that does not require any type of pre- or postprocessing or any prior knowledge on wavelet transform. We demonstrate the benefits of embedding all these properties on three machine-learning tasks performed on open-source sound datasets. We perform an ablation study of the impact of each property on the performance of the architecture, achieve results well above baseline, and outperform other state-of-the-art methods.},
   author = {Gabriel Michau and Gaetan Frusque and Olga Fink},
   doi = {10.1073/pnas.2106598119},
   issn = {10916490},
   issue = {8},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   keywords = {Deep learning,Fast discrete wavelet decomposition,High-frequency signals,Sparse decomposition,Unsupervised anomaly detection},
   month = {2},
   pmid = {35181603},
   publisher = {National Academy of Sciences},
   title = {Fully learnable deep wavelet transform for unsupervised monitoring of high-frequency time series},
   volume = {119},
   year = {2022},
}

@inproceedings{sincnet,
  title={Speaker recognition from raw waveform with sincnet},
  author={Ravanelli, Mirco and Bengio, Yoshua},
  booktitle={2018 IEEE spoken language technology workshop (SLT)},
  pages={1021--1028},
  year={2018},
  organization={IEEE}
}

@misc{mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, Chris and others},
  year={2010},
  publisher={Florham Park, NJ, USA}
}

@article{lda,
author = {Fisher, R. A.},
title = {THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS},
journal = {Annals of Eugenics},
volume = {7},
number = {2},
pages = {179-188},
doi = {https://doi.org/10.1111/j.1469-1809.1936.tb02137.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
year = {1936}
}





@misc{adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{separablecnn,
  title={Efficient convolution neural networks for object tracking using separable convolution and filter pruning},
  author={Mao, Yuanhong and He, Zhanzhuang and Ma, Zhong and Tang, Xuehan and Wang, Zhuping},
  journal={IEEE Access},
  volume={7},
  pages={106466--106474},
  year={2019},
  publisher={IEEE}
}

@misc{batchnorm,
      title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}, 
      author={Sergey Ioffe and Christian Szegedy},
      year={2015},
      eprint={1502.03167},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{relu,
      title={Deep Learning using Rectified Linear Units (ReLU)}, 
      author={Abien Fred Agarap},
      year={2019},
      eprint={1803.08375},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}