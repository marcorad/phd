% paper 1

@article{entropyorig,
	doi = {10.1088/0305-4470/12/11/017},
	url = {https://doi.org/10.1088/0305-4470/12/11/017},
	year = 1979,
	month = {nov},
	publisher = {{IOP} Publishing},
	volume = {12},
	number = {11},
	pages = {2053--2071},
	author = {G E Powell and I C Percival},
	title = {A spectral entropy method for distinguishing regular and irregular motion of Hamiltonian systems},
	journal = {Journal of Physics A: Mathematical and General},
	abstract = {Regular and irregular motions of bounded conservative Hamiltonian systems of N degrees of freedom can be distinguished by the structure of the frequency spectrum of a single trajectory. The spectral entropy S is introduced which provides a measure of the distribution of the frequency components. Numerical calculations on the model Henon and Heiles system and a realistic molecular model are performed. Power spectra are obtained from numerical solutions to Hamilton's equations using fast Fourier transforms and the Hanning method. For regular trajectories S is found to stabilise after a finite time of integration, while for irregular cases S increases erratically. Estimates of the relative volume of regular regions of phase space as a function of energy are given for the two systems.}
}


@article{entropyJASA,
	author = {Erbe,Christine  and King,Andrew R. },
	title = {Automatic detection of marine mammals using information entropy},
	journal = {The Journal of the Acoustical Society of America},
	volume = {124},
	number = {5},
	pages = {2833-2840},
	year = {2008},
	doi = {10.1121/1.2982368},	
	URL = { 
	https://doi.org/10.1121/1.2982368	
	},
	eprint = { 
	https://doi.org/10.1121/1.2982368	
	}	
}

@INPROCEEDINGS{entropyOCEANS,  author={Qiao, Gang and Ma, Tianlong and Liu, Songzuo and Zheng, Naihua and Babar, Zeeshan and Yin, Yanling},  booktitle={OCEANS 2019 - Marseille},   title={Spectral Entropy Based Dolphin Whistle Detection Algorithm and Its Possible Application for Biologically Inspired Communication},   year={2019},  volume={},  number={},  pages={1-6},  doi={10.1109/OCEANSE.2019.8866876}}

@INPROCEEDINGS{entropysubband,  author={Jin, Li and Cheng, Jiang},  booktitle={2010 International Conference on Intelligent Computation Technology and Automation},   title={An Improved Speech Endpoint Detection Based on Spectral Subtraction and Adaptive Sub-band Spectral Entropy},   year={2010},  volume={1},  number={},  pages={591-594},  doi={10.1109/ICICTA.2010.309}}

@article{shannon,
	title={A mathematical theory of communication},
	author={Shannon, Claude Elwood},
	journal={ACM SIGMOBILE mobile computing and communications review},
	volume={5},
	number={1},
	pages={3--55},
	year={2001},
	publisher={ACM New York, NY, USA}
}

@ARTICLE{detectionGLRT,
	author={Urazghildiiev, Ildar R. and Clark, Christopher W. and Krein, Timothy P. and Parks, Susan E.},
	journal={IEEE Journal of Oceanic Engineering}, 
	title={Detection and Recognition of North Atlantic Right Whale Contact Calls in the Presence of Ambient Noise}, 
	year={2009},
	volume={34},
	number={3},
	pages={358-368},
	doi={10.1109/JOE.2009.2014931}}

@Article{cwtentropy1,
	AUTHOR = {Civera, Marco and Surace, Cecilia},
	TITLE = {An Application of Instantaneous Spectral Entropy for the Condition Monitoring of Wind Turbines},
	JOURNAL = {Applied Sciences},
	VOLUME = {12},
	YEAR = {2022},
	NUMBER = {3},
	ARTICLE-NUMBER = {1059},
	URL = {https://www.mdpi.com/2076-3417/12/3/1059},
	ISSN = {2076-3417},
	ABSTRACT = {For economic and environmental reasons, the use of renewable energy sources is a key aspect of the ongoing transition to a sustainable industrialised society. Wind energy represents a major player among these natural, carbon-neutral sources. Nevertheless, wind turbines are often subject to mechanical faults, especially due to ageing. To alleviate Operation and Maintenance costs, Vibration-Based Inspection and Condition Monitoring have been proposed in recent times. This research proposes Instantaneous Spectral Entropy and Continuous Wavelet Transform for anomaly detection and fault diagnosis, departing from gearbox vibration time histories. The approach is validated on experimental data recorded from a turbine suffering bearing failure and total gearbox replacement. From a computational point of view, the proposed algorithm was found to be efficient and therefore even potentially applicable for real-time monitoring.},
	DOI = {10.3390/app12031059}
}

@Article{cwtentropy2,
	AUTHOR = {Civera, Marco and Surace, Cecilia},
	TITLE = {Instantaneous Spectral Entropy: An Application for the Online Monitoring of Multi-Storey Frame Structures},
	JOURNAL = {Buildings},
	VOLUME = {12},
	YEAR = {2022},
	NUMBER = {3},
	ARTICLE-NUMBER = {310},
	URL = {https://www.mdpi.com/2075-5309/12/3/310},
	ISSN = {2075-5309},
	ABSTRACT = {Damage assessment techniques based on entropy measurements have been recently proposed for the structural health monitoring of civil structures and infrastructures. A quasi-real-time approach, based on the use of instantaneous spectral entropy (ISE) over an uninterrupted stream of data, is discussed here. The methodology is proposed for the detection of sudden damage-related structural changes (more specifically, linear stiffness reductions and nonlinear breathing cracks). The method operates by framing the continuous stream of vibration signals and comparing the single frames to a known baseline. The approach is also suitable for nonstationary signals originating from nonlinearly behaving structures. The procedure is validated on an experimental benchmark: a laboratory-scaled model of a three-storey single-span frame metallic structure. Three different definitions of entropy and six candidate time&ndash;frequency/time-scale transforms have been tested to find the optimal settings.},
	DOI = {10.3390/buildings12030310}
}

@book{waveletbook,
	author = {Mallat, Stphane},
	title = {A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way},
	year = {2008},
	isbn = {0123743702},
	publisher = {Academic Press, Inc.},
	address = {USA},
	edition = {3rd},
	abstract = {Mallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford UniversityThe new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications.Features:* Balances presentation of the mathematics with applications to signal processing* Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox* Companion website for instructors and selected solutions and code available for studentsNew in this edition* Sparse signal representations in dictionaries* Compressive sensing, super-resolution and source separation* Geometric image processing with curvelets and bandlets* Wavelets for computer graphics with lifting on surfaces* Time-frequency audio processing and denoising* Image compression with JPEG-2000* New and updated exercisesA Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R&D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering.Stephane Mallat is Professor in Applied Mathematics at cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company.Companion website: A Numerical Tour of Signal Processing Includes all the latest developments since the book was published in 1999, including itsapplication to JPEG 2000 and MPEG-4Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolboxBalances presentation of the mathematics with applications to signal processing}
}

@ARTICLE{morsewavelets,
	author={Olhede, S.C. and Walden, A.T.},
	journal={IEEE Transactions on Signal Processing}, 
	title={Generalized Morse wavelets}, 
	year={2002},
	volume={50},
	number={11},
	pages={2661-2670},
	doi={10.1109/TSP.2002.804066}}

@article{morsewavelets2,
	title={Generalized Morse wavelets as a superfamily of analytic wavelets},
	author={Lilly, Jonathan M and Olhede, Sofia C},
	journal={IEEE Transactions on Signal Processing},
	volume={60},
	number={11},
	pages={6036--6041},
	year={2012},
	publisher={IEEE}
}

@misc{cwtmatlab, title={Continuous 1-D wavelet transform}, url={https://www.mathworks.com/help/wavelet/ref/cwt.html}, publisher={MATLAB}, author={MATLAB}, year = {n.d.}} 

@misc{raven, title={Band-limited energy detector (BLED) diagnostics}, url={https://ravensoundsoftware.com/knowledge-base/diagnostics-for-band-limited-energy-detector/}, publisher={{Cornell University}}, author={{Cornell University}}, year = {n.d.}} 

@misc{PAMGuard, title={PAMGuard core plug-in modules}, url={https://www.pamguard.org/11_PluginModules.html}, publisher={{PAMGuard}}, author={{PAMGuard}}, year = {n.d.}} 
 
 @Article{fcwt,
 	author={Arts, Lukas P. A.
 	and van den Broek, Egon. L.},
 	title={The fast continuous wavelet transformation (fCWT) for real-time, high-quality, noise-resistant time--frequency analysis},
 	journal={Nature Computational Science},
 	year={2022},
 	month={Jan},
 	day={01},
 	volume={2},
 	number={1},
 	pages={47-58},
 	abstract={The spectral analysis of signals is currently either dominated by the speed--accuracy trade-off or ignores a signal's often non-stationary character. Here we introduce an open-source algorithm to calculate the fast continuous wavelet transform (fCWT). The parallel environment of fCWT separates scale-independent and scale-dependent operations, while utilizing optimized fast Fourier transforms that exploit downsampled wavelets. fCWT is benchmarked for speed against eight competitive algorithms, tested on noise resistance and validated on synthetic electroencephalography and in vivo extracellular local field potential data. fCWT is shown to have the accuracy of CWT, to have 100 times higher spectral resolution than algorithms equal in speed, to be 122 times and 34 times faster than the reference and fastest state-of-the-art implementations and we demonstrate its real-time performance, as confirmed by the real-time analysis ratio. fCWT provides an improved balance between speed and accuracy, which enables real-time, wide-band, high-quality, time--frequency analysis of non-stationary noisy signals.},
 	issn={2662-8457},
 	doi={10.1038/s43588-021-00183-z},
 	url={https://doi.org/10.1038/s43588-021-00183-z}
 }
 
 
 @ARTICLE{glider,
 	author={Van Uffelen, Lora J. and Roth, Ethan H and Howe, Bruce M. and Oleson, Erin M. and Barkley, Yvonne},
 	journal={IEEE Journal of Oceanic Engineering}, 
 	title={A Seaglider-Integrated Digital Monitor for Bioacoustic Sensing}, 
 	year={2017},
 	volume={42},
 	number={4},
 	pages={800-807},
 	doi={10.1109/JOE.2016.2637199}}
 
 @ARTICLE{rightdetection,  author={Mohammad, Bashar and McHugh, Ronald},  journal={IEEE Journal of Oceanic Engineering},   title={Automatic Detection and Characterization of Dispersive North Atlantic Right Whale Upcalls Recorded in a Shallow-Water Environment Using a Region-Based Active Contour Model},   year={2011},  volume={36},  number={3},  pages={431-440},  doi={10.1109/JOE.2010.2060790}}

@inbook{kmeansoverview,
	author = {Ortega, Joaquín and Almanza-Ortega, Nelva and Vega-Villalobos, Andrea and Pazos-Rangel, Rodolfo and Zavala-Diaz, José Crispin and Martínez-Rebollar, Alicia},
	year = {2019},
	month = {04},
	title = {The K-Means Algorithm Evolution},
	isbn = {978-1-83880-333-9},
	doi = {10.5772/intechopen.85447}
}

@inproceedings{kmeans,
	title={Classification and analysis of multivariate observations},
	author={MacQueen, J},
	booktitle={5th Berkeley Symp. Math. Statist. Probability},
	pages={281--297},
	year={1967}
}

@article{mf1,
	title={Median filtering: Statistical properties},
	author={Justusson, BI},
	journal={Two-Dimensional Digital Signal Prcessing II},
	pages={161--196},
	year={1981},
	publisher={Springer}
}

@INPROCEEDINGS{mf2,  author={George, Ginu and Oommen, Rinoy Mathew and Shelly, Shani and Philipose, Stephie Sara and Varghese, Ann Mary},  booktitle={2018 Conference on Emerging Devices and Smart Systems (ICEDSS)},   title={A Survey on Various Median Filtering Techniques For Removal of Impulse Noise From Digital Image},   year={2018},  volume={},  number={},  pages={235-238},  doi={10.1109/ICEDSS.2018.8544273}}

@article{maxentropy,
	title={Probability distributions and maximum entropy},
	author={Conrad, Keith},
	journal={Entropy},
	volume={6},
	number={452},
	pages={10},
	year={2004}
}

@ARTICLE{whalemodel,  author={Frazer, L.N. and Mercado, E.},  journal={IEEE Journal of Oceanic Engineering},   title={A sonar model for humpback whale song},   year={2000},  volume={25},  number={1},  pages={160-182},  doi={10.1109/48.820748}}


@article{hydrophone,
	author = {Au,Whitlow W. L.  and Pack,Adam A.  and Lammers,Marc O.  and Herman,Louis M.  and Deakos,Mark H.  and Andrews,Kim },
	title = {Acoustic properties of humpback whale songs},
	journal = {The Journal of the Acoustical Society of America},
	volume = {120},
	number = {2},
	pages = {1103-1110},
	year = {2006},
	doi = {10.1121/1.2211547},
	
	URL = { 
	https://doi.org/10.1121/1.2211547
	
	},
	eprint = { 
	https://doi.org/10.1121/1.2211547
	
	}
	
}

@article{dolphindetection,
title = {Active contour-based detection of estuarine dolphin whistles in spectrogram images},
journal = {Ecological Informatics},
volume = {55},
pages = {101036},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2019.101036},
url = {https://www.sciencedirect.com/science/article/pii/S1574954119303462},
author = {O.M. Serra and F.P.R. Martins and L.R. Padovese},
keywords = {(, Spectrogram, Hough transform, Active contours, Random forest, Machine learning)},
abstract = {An algorithm for detecting tonal vocalizations from estuarine dolphin (Sotalia guianensis) specimens without interference of a human operator was developed. The raw audio data collected from a passive monitoring sensor in the Cananéia underwater soundscape was converted to spectrogram images. Detection is a four-step method: first, ridge maps are obtained from the spectrogram images; second, a probabilistic Hough transform algorithm is applied to detect ridges similar to thick line segments, referred to as line-like, which are adjusted to the geometry of the whistles in the images via an active contour algorithm; third, feature vectors are built from the geometry of each detected whistle, with 9 descriptive features; and fourth, the detections are fed to a random forest classifier to parse out mistakes by the detection process. We developed a system for classifying the characteristic patterns detected as Sotalia guianensis whistles or random empty detections. We obtained accuracy of 0.977 and F1-score of 0.981.}
}

@article{internalsignaldetection,
title = {Temporal separation of whale vocalizations from background oceanic noise using a power calculation},
journal = {Ecological Informatics},
volume = {69},
pages = {101627},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101627},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122000760},
author = {Jacques {van Wyk} and Johan {du Preez} and Jaco Versfeld},
keywords = {Gaussian noise, Detection, Whale vocalizations, Power, Variance, Segmentation},
abstract = {The process of analyzing audio signals in search of cetacean vocalizations is in many cases a very arduous task, requiring many complex computations, a plethora of digital processing techniques and the scrutinization of an audio signal with a fine comb to determine where the vocalizations are located. To ease this process, a computationally efficient and noise-resistant method for determining whether an audio segment contains a potential cetacean call is developed here with the help of a robust power calculation for stationary Gaussian noise signals and a recursive method for determining the mean and variance of a given sample frame. The resulting detector is tested on audio recordings containing southern right whale sounds and its performance is compared to a contemporary energy detector and a popular deep learning method. The detector exhibits good performance at moderate-to-high signal-to-noise ratio values. The detector succeeds in being easy to implement, computationally efficient to use and robust enough to accurately detect whale vocalizations in a noisy underwater environment.}
}

@article{logit,
  title={The origins of logistic regression},
  author={Cramer, Jan Salomon},
  year={2002},
  publisher={Tinbergen Institute Working Paper}
}

@article{MLalexnet,
title = {Detection and classification of marine mammal sounds using AlexNet with transfer learning},
journal = {Ecological Informatics},
volume = {62},
pages = {101277},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101277},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000686},
author = {Tao Lu and Baokun Han and Fanqianhui Yu},
keywords = {Marine mammal sounds, AlexNet, Transfer learning, Feature visualization, Strongest activations},
abstract = {In this study, AlexNet with transfer learning was employed to automatically detect and classify the sounds of killer whales, long-finned pilot whales, and harp seals with widely overlapping living areas. Transfer learning was used to overcome the overfitting problem of deep network as the training samples was insufficient. A challenging dataset containing both target (the three marine mammal sounds) and non-target (ambient noise including ship noise, pulse interference, and man-made sounds, etc) sounds collected from different recording times, locations and devices was used to examine the performance of the proposed method, and the sounds used in the test dataset were completely independent of the training dataset. The overall accuracy of the trained detection and classification models reached 99.96\% and 97.42\% respectively. Importantly, each trained model took only 1.3 ms to detect or classify a single image. Furthermore, feature visualizations and strongest activations demonstrated that the proposed method learns the true differences between different marine mammal sounds rather than differences between different recording environments and devices. Therefore, all results show that the proposed method has excellent performance and great potential for practical application.}
}

@article{MLcnn,
title = {Whistle detection and classification for whales based on convolutional neural networks},
journal = {Applied Acoustics},
volume = {150},
pages = {169-178},
year = {2019},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2019.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X18311241},
author = {Jia-jia Jiang and Ling-ran Bu and Fa-jie Duan and Xian-quan Wang and Wei Liu and Zhong-bo Sun and Chun-yue Li},
abstract = {Passive acoustic observation of whales is an increasingly important tool for whale research. Accurately detecting whale sounds and correctly classifying them into corresponding whale species are essential tasks, especially in the case when two species of whales vocalize in the same observed area. Whistles are vital vocalizations of toothed whales, such as killer whales and long-finned pilot whales. In this paper, based on deep convolutional neural networks (CNNs), a novel method is proposed to detect and classify whistles of both killer whales and long-finned pilot whales. Compared with traditional methods, the proposed one can automatically learn the sound characteristics from the training data, without specifying the sound features for classification and detection, and thus shows better adaptability to complex sound signals. First, the denoised sound to be analyzed is sent to the trained detection model to estimate the number and positions of the target whistles. The detected whistles are then sent to the trained classification model, which determines the corresponding whale species. A GUI interface is developed to assist with the detection and classification process. Experimental results show that the proposed method can achieve 97\% correct detection rate and 95\% correct classification rate on the testing set. In the future, the presented method can be further applied to passive acoustic observation applications for some other whale or dolphin species.}
}

@article{hmm1,
title = {Detection of baleen whale species using kernel dynamic mode decomposition-based feature extraction with a hidden Markov model},
journal = {Ecological Informatics},
volume = {71},
pages = {101766},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101766},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122002163},
author = {A.M. Usman and D.J.J. Versfeld},
keywords = {Baleen whales, Detection, DMD, Eigendecomposition, Error rate, Feature extraction, HMM, Kernel DMD, Precision, True positive rate},
abstract = {The negative effects of human activities within the ecological space of whales remains an issue of concern to marine ecologists. The accurate detection and subsequent classification of whale species are vital in mitigating these negative effects. Automatic detection techniques have come in handy for the efficient detection of the various whale species without human error. Hidden Markov model (HMM) remains one the most efficient detectors of whale species. However, its performance efficiency is greatly influenced by the feature vectors adapted with it. In this work, we propose the use of the kernel dynamic mode decomposition (kDMD) algorithm as a tool to extract features of baleen whale species, which are then adapted with HMM for their detection. Dynamic mode decomposition (DMD) is an eigendecomposition-based algorithm that is capable of extracting latent underlying features of non-linear signals such as those vocalised by whales. However, the underlying cost of DMD is the singular value decomposition (SVD), which adds significant complexity to the modes derivation steps. Thus, this work is introducing the kernel method into the DMD, in order to find a more efficient way of computing DMD without explicitly using the SVD algorithm. Furthermore, the feature formation steps in the original DMD was modified (mDMD) in this work, to make it more generic for datasets with sparse whale sound samples. The performance of the detectors was tested on datasets containing sounds of southern right whales (SRWs) and humpback whales. The results obtained show a high true positive rate (TPR), high precision (PREC) and low error rate (ERR) for both species. The performance of the three DMD-based feature-extraction methods were compared. The kDMD-HMM generally performed better than the mDMD-HMM and DMD-HMM detectors. The methods proposed here can be tailored for the automatic detection and classification of other vocalising animal species through their sounds.}
}

@article{hmm2,
title = {A hidden Markov model with selective time domain feature extraction to detect inshore Bryde's whale short pulse calls},
journal = {Ecological Informatics},
volume = {57},
pages = {101087},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101087},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120300376},
author = {O.O. Ogundile and A.M. Usman and O.P. Babalola and D.J.J. Versfeld},
keywords = {Bryde's whale, HMM, LPC, MAP, MFCC, Sound detection},
abstract = {An Increase in the study of cetaceans' sounds has motivated the development of different automated sound detection and classification techniques. Passive acoustic monitoring (PAM) is extensively used to study these cetaceans' sounds over a period to understand their daily activities within their ecosystem. Using PAM, the gathered sound datasets are usually large and impractical to manually analyse and detect. Thus, hidden Markov models (HMM) is one of the popular tools used to automatically detect and classify these cetaceans' sounds. Nonetheless, HMM rely heavily on the employed feature extraction method such as Mel-scale frequency cepstral coefficients (MFCC) and linear predictive coding (LPC). In most cases, the more reliable the extracted feature vector from the known sound label, the higher the sensitivity of the HMM. Although these aforementioned feature extraction methods are widely used, their design is based on filters and requires windowing, fast Fourier transforms (FFT), and logarithm operations. Consequently, this increases the computational time complexity of the HMM. Here, we describe a selective time domain feature extraction method that can be easily adapted with the HMM. This proposed feature extraction method uses a combination of some simple but robust parameters such as the mean, relative amplitude and relative power/energy (MAP), which are selected based on empirical observations of the call to be detected. The performance of this proposed MAP-HMM was verified using the acoustic dataset of continuous recordings of an inshore Bryde's whale (Balaenoptera) short pulse calls collected in a single site in False bay, South-West of South Africa. Aside from exhibiting a low computational complexity, the proposed MAP-HMM offers superior sensitivity and false discovery rate performances in comparison to the LPC-HMM and MFCC-HMM.}
}

@article{hmm3,
title = {Dynamic mode decomposition: A feature extraction technique based hidden Markov model for detection of Mysticetes' vocalisations},
journal = {Ecological Informatics},
volume = {63},
pages = {101306},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101306},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000972},
author = {O.O. Ogundile and A.M. Usman and O.P. Babalola and D.J.J. Versfeld},
keywords = {Detection, DMD, EMD, FDR, HMM, LPC, MFCC, , Pulse calls, Sensitivity, Songs},
abstract = {The detection and classification of Mysticetes' vocalisations have evoked the attention of researchers over the years because of their relevance to the marine ecosystem. These vocalisations are gathered employing different passive acoustic monitoring techniques. The vocalisation datasets are accumulated over a period; thus, they are large and cannot be easily analysed manually. Consequently, efficient machine learning (ML) tools such as the hidden Markov models (HMMs) are used extensively to automatically detect and classify these huge vocalisation datasets. As with most ML tools, the detection efficiency of the HMMs depend on the adopted feature extraction technique. Feature extraction techniques such as the Mel-scale frequency cepstral coefficient (MFCC), linear predictive coefficient (LPC), and empirical mode decomposition (EMD) have been adopted with the HMMs to detect different Mysticetes' vocalisations. This article introduces the method of dynamic mode decomposition (DMD) as a feature extraction technique that can be adopted with the HMMs for the detection of Mysticetes' vocalisations. The DMD has emerged as a robust tool for analysing the dynamics of non-stationary and non-linear signals. It is a completely data-driven tool that decomposes a signal over a certain period of time into relevant modes. Here, these spatial-temporal modes are reconstructed mathematically to form reliable feature vectors of the decomposed vocalisation signals. The performance of the proposed DMD-HMM detection technique is demonstrated using the acoustic datasets of two different Mysticetes' vocalisations: Humpback whale songs and Inshore Bryde's whale short pulse calls. In both species, the proposed DMD-HMM exhibits superior sensitivity and false discovery rate performances as compared to the MFCC-HMM, LPC-HMM, and EMD-HMM detection methods. Likewise, this proposed DMD-HMM detection method can be extended to other Mysticetes' that produce characteristics sounds.}
}

@article{unsupervised,
title = {Model-based unsupervised clustering for distinguishing Cuvier's and Gervais' beaked whales in acoustic data},
journal = {Ecological Informatics},
volume = {58},
pages = {101094},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101094},
url = {https://www.sciencedirect.com/science/article/pii/S1574954120300443},
author = {Kun Li and Natalia A. Sidorovskaia and Christopher O. Tiemann},
keywords = {Underwater acoustics, Beaked whale, Machine learning, Signal processing},
abstract = {Passive acoustic monitoring (PAM), particularly autonomous platforms, offers many advantages in monitoring phonating deep-diving marine mammals in oceanic environment. Relevant data can be obtained day and night continuously over long durations and in any weather conditions. It provides a cost-efficient solution with greater detection ranges when compared to traditional large research vessel and aerial visual surveys requiring keeping expert observers on station for long periods of time and relying on good visibility and calm seas. Therefore, PAM is becoming a preferred tool to assess population dynamics trends and health of deep-water marine mammal stocks. However the large volumes of collected data require robust automatic detection and classification algorithms to identify marine mammals in recordings. As for beaked whales, one of the challenging automatic processing goals is the identification of different species to advance our understanding of their role in the marine ecosystem. At present, traditional detection and classification methods employ searches for acoustic events above a user-defined signal-to-noise ratio threshold in the frequency band of interest and further rely on an experienced operator's manual inspection for species classification and removal of false positives. Current passive monitoring data collection systems yield large volumes of acoustic data, therefore a manual classification approach becomes very time-consuming and impractical. This paper focuses on developing a multi-stage automatic classifier for beaked whale species. The proposed method utilizes unsupervised machine clustering of signal attributes extracted from potential detection events flagged by an energy-band detector. The proposed algorithm was benchmarked against a manually annotated workshop dataset and applied to acoustic data collected in the northern Gulf of Mexico. The algorithm classifies beaked whale species in automatic mode with minimal operator involvement only at the validation stage. When compared with the manually annotated classification dataset, the proposed method achieved a recall rate of 82.8\% for Cuvier's and 77.9\% for Gervais' species in automatic mode. New insights on habitat use by different species of beaked whales in the Gulf of Mexico were gained when using the species-specific classifier. The high spatial resolution acoustic monitoring results showed that the habitat preferences of two dominating beaked whale species in the Gulf of Mexico support the habitat division (ecological niche) hypothesis.}
}

@INPROCEEDINGS{denoising,
  author={Jun Jiang and Jian Guo and Weihua Fan and Qingwei Chen},
  booktitle={2010 8th World Congress on Intelligent Control and Automation}, 
  title={An improved adaptive wavelet denoising method based on neighboring coefficients}, 
  year={2010},
  volume={},
  number={},
  pages={2894-2898},
  doi={10.1109/WCICA.2010.5554856}}

@ARTICLE{frequencyestimation,
  author={Mingyang Wu and DeLiang Wang and Brown, G.J.},
  journal={IEEE Transactions on Speech and Audio Processing}, 
  title={A multipitch tracking algorithm for noisy speech}, 
  year={2003},
  volume={11},
  number={3},
  pages={229-241},
  doi={10.1109/TSA.2003.811539}}

  @INPROCEEDINGS{denoiseSSN,
  author={Ganapathi, Sumithra and Kumar, Suresh Minakanoor and Deivasigamani, Meganathan},
  booktitle={2016 IEEE/OES China Ocean Acoustics (COA)}, 
  title={Noise reduction in underwater acoustic signals for tropical and subtropical coastal waters}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/COA.2016.7535678}}

  @book{vantrees,
  title={Detection Estimation and Modulation Theory, Part I: Detection, Estimation, and Filtering Theory},
  author={Van Trees, H.L. and Tian, Z. and Bell, K.L.},
  isbn={9781118539705},
  lccn={2012036672},
  series={Detection Estimation and Modulation Theory},
  url={https://books.google.co.za/books?id=dnvaxqHDkbQC},
  year={2013},
  publisher={Wiley}
}

@article{ecgcwt,
title = {Automatic classification of electrocardiogram signals based on transfer learning and continuous wavelet transform},
journal = {Ecological Informatics},
volume = {69},
pages = {101628},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2022.101628},
url = {https://www.sciencedirect.com/science/article/pii/S1574954122000772},
author = {Xiaoming Sun and Pengfei Liu and Zhishuai He and Yang Han and Bochao Su},
keywords = {Heartbeat classification, Arrhythmia, Transfer learning, Convolutional neural network, Continuous wavelet transform},
}

@article{lakelevelcwt,
title = {Investigation of climate, land cover and lake level pattern changes and interactions using remotely sensed data and wavelet analysis},
journal = {Ecological Informatics},
volume = {64},
pages = {101330},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101330},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121001217},
author = {Vahid Nourani and Roshanak Tootoonchi and Soghra Andaryani},
keywords = {Hydro-climatic processes, Anthropogenic activities, Land cover, Satellite imagery, Wavelet analysis, Lake urmia},
}

@article{seismiccwt,
title = {Seismic signal analysis for the characterisation of elephant movements in a forest environment},
journal = {Ecological Informatics},
volume = {64},
pages = {101329},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101329},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121001205},
author = {D.S. Parihar and Ripul Ghosh and Aparna Akula and Satish Kumar and H.K. Sardana},
keywords = {ASFT, Continuous wavelet transform, Elephant detection, FFT, Seismic signal analysis, Signal processing, STA/LTA},
}

 

% paper 2

@article{casey2019,
  abstract  = {The source levels, SL, of Antarctic blue and fin whale calls were estimated using acoustic recordings collected from directional sonobuoys deployed during an Antarctic voyage in 2019. Antarctic blue whale call types included stereotyped song and downswept frequency-modulated calls, often, respectively, referred to as Z-calls (comprising song units-A, B, and C) and D-calls. Fin whale calls included 20 Hz pulses and 40 Hz downswept calls. Source levels were obtained by measuring received levels (RL) and modelling transmission losses (TL) for each detection. Estimates of SL were sensitive to the parameters used in TL models, particularly the seafloor geoacoustic properties and depth of the calling whale. For our best estimate of TL and whale-depth, mean SL in dB re 1 μPa ± 1 standard deviation ranged between 188–191 ± 6–8 dB for blue whale call types and 189–192 ± 6 dB for fin whale call types. These estimates of SL are the first from the Southern Hemisphere for D-calls and 40 Hz downsweeps, and the largest sample size to-date for Antarctic blue whale song. Knowledge of source levels is essential for estimating the detection range and communication space of these calls and will enable more accurate comparisons of detections of these sounds from sonobuoy surveys and across international long-term monitoring networks.},
  author    = {Brian S. Miller and Susannah Calderan and Russell Leaper and Elanor J. Miller and Ana Širović and Kathleen M. Stafford and Elanor Bell and Michael C. Double},
  doi       = {10.3389/fmars.2021.792651},
  issn      = {22967745},
  journal   = {Frontiers in Marine Science},
  keywords  = {Antarctic,bioacoustics,blue whale (Balaenoptera musculus),fin whale (Balaenoptera physalus),sonobuoy,source level,vocalizations},
  month     = {12},
  note      = {Casey2019 DS},
  publisher = {Frontiers Media S.A.},
  title     = {Source Level of Antarctic Blue and Fin Whale Sounds Recorded on Sonobuoys Deployed in the Deep-Ocean Off Antarctica},
  volume    = {8},
  year      = {2021}
}

@article{casey2017,
  abstract  = {Since 2001, hundreds of thousands of hours of underwater acoustic recordings have been made throughout the Southern Ocean south of 60° S. Detailed analysis of the occurrence of marine mammal sounds in these circumpolar recordings could provide novel insights into their ecology, but manual inspection of the entirety of all recordings would be prohibitively time consuming and expensive. Automated signal processing methods have now developed to the point that they can be applied to these data in a cost-effective manner. However training and evaluating the efficacy of these automated signal processing methods still requires a representative annotated library of sounds to identify the true presence and absence of different sound types. This work presents such a library of annotated recordings for the purpose of training and evaluating automated detectors of Antarctic blue and fin whale calls. Creation of the library has focused on the annotation of a representative sample of recordings to ensure that automated algorithms can be developed and tested across a broad range of instruments, locations, environmental conditions, and years. To demonstrate the utility of the library, we characterise the performance of two automated detection algorithms that have been commonly used to detect stereotyped calls of blue and fin whales. The availability of this library will facilitate development of improved detectors for the acoustic presence of Southern Ocean blue and fin whales. It can also be expanded upon to facilitate standardization of subsequent analysis of spatiotemporal trends in call-density of these circumpolar species.},
  author    = {Brian S. Miller and Kathleen M. Stafford and Ilse Van Opzeeland and Danielle Harris and Flore Samaran and Ana Širović and Susannah Buchan and Ken Findlay and Naysa Balcazar and Sharon Nieukirk and Emmanuelle C. Leroy and Meghan Aulich and Fannie W. Shabangu and Robert P. Dziak and Won Sang Lee and Jong Kuk Hong},
  doi       = {10.1038/s41598-020-78995-8},
  issn      = {20452322},
  issue     = {1},
  journal   = {Scientific Reports},
  month     = {12},
  pmid      = {33436710},
  publisher = {Nature Research},
  title     = {An open access dataset for developing automated detectors of Antarctic baleen whale sounds and performance evaluation of two commonly used detectors},
  volume    = {11},
  year      = {2021}
}


@misc{MLreview,
  abstract  = {Machine learning (ML) refers to computer algorithms that predict a meaningful output or categorize complex systems based on a large amount of data. ML is applied in various areas including natural science, engineering, space exploration, and even gaming development. This review focuses on the use of machine learning in the field of chemical and biological oceanography. In the prediction of global fixed nitrogen levels, partial carbon dioxide pressure, and other chemical properties, the application of ML is a promising tool. Machine learning is also utilized in the field of biological oceanography to detect planktonic forms from various images (i.e., microscopy, FlowCAM, and video recorders), spectrometers, and other signal processing techniques. Moreover, ML successfully classified the mammals using their acoustics, detecting endangered mammalian and fish species in a specific environment. Most importantly, using environmental data, the ML proved to be an effective method for predicting hypoxic conditions and harmful algal bloom events, an essential measurement in terms of environmental monitoring. Furthermore, machine learning was used to construct a number of databases for various species that will be useful to other researchers, and the creation of new algorithms will help the marine research community better comprehend the chemistry and biology of the ocean.},
  author    = {Balamurugan Sadaiappan and Preethiya Balakrishnan and C. R. Vishal and Neethu T. Vijayan and Mahendran Subramanian and Mangesh U. Gauns},
  doi       = {10.1021/acsomega.2c06441},
  issn      = {24701343},
  issue     = {18},
  journal   = {ACS Omega},
  month     = {5},
  pages     = {15831-15853},
  publisher = {American Chemical Society},
  title     = {Applications of Machine Learning in Chemical and Biological Oceanography},
  volume    = {8},
  year      = {2023}
}

@article{otherScattering,
  abstract  = {In this paper, we study to improve acoustical methods to identify endangered whale calls with emphasis on the blue whale (Balaenoptera musculus) and fin whale (Balaenoptera physalus). A promising method using wavelet scattering transform and deep learning is proposed here to detect/classify the whale calls quite precisely in the increasingly noisy ocean with a small dataset. The performances shown in terms of classification accuracy (>97%) demonstrate the efficiency of the proposed method which outperforms the relevant state-of-the-art methods. In this way, passive acoustic technology can be enhanced to monitor endangered whale calls. Efficient tracking of their numbers, migration paths and habitat become vital to whale conservation by lowering the number of preventable injuries and deaths while making progress in their recovery.},
  author    = {Farook Sattar},
  doi       = {10.3390/s23063048},
  issn      = {14248220},
  issue     = {6},
  journal   = {Sensors},
  keywords  = {artificial intelligence,deep learning,endangered whale,identification,marine bioacoustics,small data set,wavelet scattering transform,whale calls},
  month     = {3},
  pmid      = {36991759},
  publisher = {MDPI},
  title     = {A New Acoustical Autonomous Method for Identifying Endangered Whale Calls: A Case Study of Blue Whale and Fin Whale},
  volume    = {23},
  year      = {2023}
}

@article{jacques1,
  abstract = {The process of analyzing audio signals in search of cetacean vocalizations is in many cases a very arduous task, requiring many complex computations, a plethora of digital processing techniques and the scrutinization of an audio signal with a fine comb to determine where the vocalizations are located. To ease this process, a computationally efficient and noise-resistant method for determining whether an audio segment contains a potential cetacean call is developed here with the help of a robust power calculation for stationary Gaussian noise signals and a recursive method for determining the mean and variance of a given sample frame. The resulting detector is tested on audio recordings containing southern right whale sounds and its performance is compared to a contemporary energy detector and a popular deep learning method. The detector exhibits good performance at moderate-to-high signal-to-noise ratio values. The detector succeeds in being easy to implement, computationally efficient to use and robust enough to accurately detect whale vocalizations in a noisy underwater environment.},
  author   = {Jacques van Wyk and Jaco Versfeld and Johan du Preez},
  doi      = {10.1016/j.ecoinf.2022.101627},
  month    = {10},
  title    = {Temporal separation of whale vocalizations from background oceanic noise using a power calculation},
  url      = {http://arxiv.org/abs/2110.10010 http://dx.doi.org/10.1016/j.ecoinf.2022.101627},
  year     = {2021}
}


@article{jacques2,
  abstract = {There is a growing interest in the ability to detect and classify animal vocalizations in large scale bioacoustic databases for the purposes of conservation and research. To aid in this, two methods are proposed for the quick and accurate detection of harmonic cetacean and fish vocalizations: Normalized summation of sound harmonics and spectrogram masking. These methods utilize a normalization scheme that enables robust performance, achieving 30% more precision and recall than traditional spectrogram cross correlation in the presence of wideband noise and low signal-to-noise ratios. The proposed methods also perform up to 135 times faster than spectrogram cross correlation.},
  author   = {Jacques van Wyk and Jaco Versfeld and Johan du Preez},
  doi      = {10.1121/10.0021021},
  issn     = {2691-1191},
  issue    = {9},
  journal  = {JASA Express Letters},
  month    = {9},
  title    = {Detection of cetacean and fish sounds using normalized summation of harmonics and spectrogram masking},
  volume   = {3},
  url      = {https://pubs.aip.org/jel/article/3/9/096002/2911548/Detection-of-cetacean-and-fish-sounds-using},
  year     = {2023}
}

@article{MFCC_HMM_birds,
  abstract  = {Hidden Markov models (HMMs) were developed and implemented to discriminate between each of the 2 ages, 11 call-types, and 51 speakers of birds using cross-validation on the recordings in the 3314 database for chick (19–25 days of age) and adult (60 days–7 years of age) vocalizations of Zebra Finches (Taeniopygia guttata). By applying both temporal [delta (velocity) and delta-delta (acceleration) coefficients] and spectral [Mel-Frequency Cepstral Coefficients (MFCCs)] features, the HMMs produced excellent performance with accuracies on the three tasks: (1) 96.68% (age recognition); (2) 94.62% (chicks) and 79.30% (adults) (call-type classification); and (3) 55.32% (12 speakers, chicks) and 16.78% (33 speakers, adults) to 100.00% (2 speakers, chicks), and 100.00% (3 speakers adults) (speaker identification). Based on the performances, the HMMs could be extended to other animals for automatic recognition, classification, and identification tasks.},
  author    = {Marek B. Trawicki},
  doi       = {10.1007/s10772-023-10041-0},
  issn      = {15728110},
  journal   = {International Journal of Speech Technology},
  keywords  = {Age recognition,Bioacoustics,Call-type classification,Hidden Markov models (HMMs),Speaker identification,Zebra Finches (Taeniopygia guttata)},
  publisher = {Springer},
  title     = {{Automatic age recognition, call-type classification, and speaker identification of Zebra Finches (Taeniopygia guttata) using hidden Markov models (HMMs)}},
  year      = {2023}
}

@article{mfcc_hmm_brydes,
  abstract  = {An Increase in the study of cetaceans' sounds has motivated the development of different automated sound detection and classification techniques. Passive acoustic monitoring (PAM) is extensively used to study these cetaceans' sounds over a period to understand their daily activities within their ecosystem. Using PAM, the gathered sound datasets are usually large and impractical to manually analyse and detect. Thus, hidden Markov models (HMM) is one of the popular tools used to automatically detect and classify these cetaceans' sounds. Nonetheless, HMM rely heavily on the employed feature extraction method such as Mel-scale frequency cepstral coefficients (MFCC) and linear predictive coding (LPC). In most cases, the more reliable the extracted feature vector from the known sound label, the higher the sensitivity of the HMM. Although these aforementioned feature extraction methods are widely used, their design is based on filters and requires windowing, fast Fourier transforms (FFT), and logarithm operations. Consequently, this increases the computational time complexity of the HMM. Here, we describe a selective time domain feature extraction method that can be easily adapted with the HMM. This proposed feature extraction method uses a combination of some simple but robust parameters such as the mean, relative amplitude and relative power/energy (MAP), which are selected based on empirical observations of the call to be detected. The performance of this proposed MAP-HMM was verified using the acoustic dataset of continuous recordings of an inshore Bryde's whale (Balaenoptera) short pulse calls collected in a single site in False bay, South-West of South Africa. Aside from exhibiting a low computational complexity, the proposed MAP-HMM offers superior sensitivity and false discovery rate performances in comparison to the LPC-HMM and MFCC-HMM.},
  author    = {O. O. Ogundile and A. M. Usman and O. P. Babalola and D. J.J. Versfeld},
  doi       = {10.1016/j.ecoinf.2020.101087},
  issn      = {15749541},
  journal   = {Ecological Informatics},
  keywords  = {Bryde's whale,HMM,LPC,MAP,MFCC,Sound detection},
  month     = {5},
  publisher = {Elsevier B.V.},
  title     = {{A hidden Markov model with selective time domain feature extraction to detect inshore Bryde's whale short pulse calls}},
  volume    = {57},
  year      = {2020}
}

@article{alexnet_killer_whales,
  abstract  = {In this study, AlexNet with transfer learning was employed to automatically detect and classify the sounds of killer whales, long-finned pilot whales, and harp seals with widely overlapping living areas. Transfer learning was used to overcome the overfitting problem of deep network as the training samples was insufficient. A challenging dataset containing both target (the three marine mammal sounds) and non-target (ambient noise including ship noise, pulse interference, and man-made sounds, etc) sounds collected from different recording times, locations and devices was used to examine the performance of the proposed method, and the sounds used in the test dataset were completely independent of the training dataset. The overall accuracy of the trained detection and classification models reached 99.96% and 97.42% respectively. Importantly, each trained model took only 1.3 ms to detect or classify a single image. Furthermore, feature visualizations and strongest activations demonstrated that the proposed method learns the true differences between different marine mammal sounds rather than differences between different recording environments and devices. Therefore, all results show that the proposed method has excellent performance and great potential for practical application.},
  author    = {Tao Lu and Baokun Han and Fanqianhui Yu},
  doi       = {10.1016/j.ecoinf.2021.101277},
  issn      = {15749541},
  journal   = {Ecological Informatics},
  keywords  = {AlexNet,Feature visualization,Marine mammal sounds,Strongest activations,Transfer learning},
  month     = {5},
  publisher = {Elsevier B.V.},
  title     = {{Detection and classification of marine mammal sounds using AlexNet with transfer learning}},
  volume    = {62},
  year      = {2021}
}

@article{cnn_multiple_whale_classes,
  abstract = {Large acoustic data sets are typically generated from ocean observations with a 160-element coherent hydrophone array and correspondingly larger volumes of acoustic detection events stem from coherent array processing. Beamforming enhances detection signal to-noise ratio, significantly improving detection ranges, as well as providing signal bearing. Here, we develop and train algorithms for the automatic detection and classification of baleen and toothed whale calls present in multiple beamformed spectrograms spanning 360 degree azimuths generated via the passive ocean acoustic waveguide remote sensing technique in the following six categories for the Gulf of Maine: Fin, Sei, Minke, Humpback, unidentified baleen whale downsweep chirps, and general toothed whale encompassing echolocation clicks and whistles below 4 kHz. The classifiers include random forest, support vector machine (SVM), and decision tree applied to hand-engineered features, as well as Convolutional Neural Network (CNN)-based model on the per-channel energy normalization transform (PCEN) applied directly to beamformed spectrogram imagery. Total accuracy of 95% and average F1-score of 85% are achieved using random forest classifier. The processing flow, including beamforming, PCEN extraction and call classification, run in real-time making the methods suitable for real-world applications, such as marine mammal monitoring and mitigation in ocean hydrocarbon prospecting and wind farm installations.},
  author   = {Hamed Mohebbi-Kalkhoran and Purnima Ratilal},
  doi      = {10.1121/10.0016331},
  issn     = {0001-4966},
  issue    = {4_Supplement},
  journal  = {The Journal of the Acoustical Society of America},
  title    = {{Automatic detection and classification of baleen and toothed whale calls via machine learning approaches over instantaneous wide areas in the Gulf of Maine received on a coherent hydrophone array}},
  volume   = {152},
  year     = {2022}
}

@article{scattering_birdsong,
  abstract  = {High-frequency (HF) signals are ubiquitous in the industrial world and are of great use for monitoring of industrial assets. Most deep-learning tools are designed for inputs of fixed and/or very limited size and many successful applications of deep learning to the industrial context use as inputs extracted features, which are a manually and often arduously obtained compact representation of the original signal. In this paper, we propose a fully unsupervised deep-learning framework that is able to extract a meaningful and sparse representation of raw HF signals. We embed in our architecture important properties of the fast discrete wavelet transform (FDWT) such as 1) the cascade algorithm; 2) the conjugate quadrature filter property that links together the wavelet, the scaling, and transposed filter functions; and 3) the coefficient denoising. Using deep learning, we make this architecture fully learnable: Both the wavelet bases and the wavelet coefficient denoising become learnable. To achieve this objective, we propose an activation function that performs a learnable hard thresholding of the wavelet coefficients. With our framework, the denoising FDWT becomes a fully learnable unsupervised tool that does not require any type of pre- or postprocessing or any prior knowledge on wavelet transform. We demonstrate the benefits of embedding all these properties on three machine-learning tasks performed on open-source sound datasets. We perform an ablation study of the impact of each property on the performance of the architecture, achieve results well above baseline, and outperform other state-of-the-art methods.},
  author    = {Gabriel Michau and Gaetan Frusque and Olga Fink},
  doi       = {10.1073/pnas.2106598119},
  issn      = {10916490},
  issue     = {8},
  journal   = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords  = {{Deep learning,Fast discrete wavelet decomposition,High-frequency signals,Sparse decomposition,Unsupervised anomaly detection}},
  month     = {2},
  pmid      = {35181603},
  publisher = {National Academy of Sciences},
  title     = {Fully learnable deep wavelet transform for unsupervised monitoring of high-frequency time series},
  volume    = {119},
  year      = {2022}
}

@article{mypaper,
  abstract  = {Underwater passive acoustic monitoring systems record many hours of audio data for marine research, making fast and reliable non-causal signal detection paramount. Such detectors assist in reducing the amount of labor required for signal annotations, which often contain large portions devoid of signals. Cetacean vocalization detection based on spectral entropy is investigated as a means of vocalization discovery. Previous techniques using spectral entropy mostly consider time–frequency enhancement of the entropy measure, and utilize the short time Fourier transform (STFT) as its time–frequency (TF) decomposition. Spectral entropy methods also requires the user to set a detection threshold manually, which call for knowledge of the produced entropy measures. This paper considers median filtering as a simple, effective way to provide temporal stabilization to the entropy measure, and considers the continuous wavelet transform (CWT) as an alternative TF decomposition. K-means clustering is used to determine the threshold required to accurately separate the signal/no-signal entropy measures, resulting in a one-dimensional, two-class classification problem. The class means are used to perform pseudo-probabilistic soft class assignment, which is a useful metric in algorithmic development. The effect of median filtering, signal-to-noise ratio and the chosen TF decomposition are investigated. The accuracy and specificity measures of the proposed detection technique are simulated using a pulsed frequency modulated sweep, corrupted by a sample of ocean noise. The results show that median filtering is particularly effective for low signal-to-noise ratios. Both the STFT and CWT prove to be effective TF analyses for signal detection purposes, each presenting with different advantages and drawbacks. The simulated results provide insight into configuring the proposed detector, which is compared to a conventional STFT-based spectral entropy detector using manually annotated humpback whale (Megaptera novaeangliae) songs recorded in False Bay, South Africa, July2021. The proposed method shows a significant improvement in detection accuracy and specificity, while also providing a more interpretable detection threshold setting via soft class assignment, providing a detector for use in development of adaptive algorithms.},
  author    = {M. W. Rademan and D. J.J. Versfeld and J. A. du Preez},
  doi       = {10.1016/j.ecoinf.2023.101990},
  issn      = {15749541},
  journal   = {Ecological Informatics},
  keywords  = {Cetacean vocalization,Continuous wavelet transform,K-means,Signal detection,Soft classification,Spectral entropy},
  month     = {5},
  publisher = {Elsevier B.V.},
  title     = {{Soft-output signal detection for cetacean vocalizations using spectral entropy, k-means clustering and the continuous wavelet transform}},
  volume    = {74},
  year      = {2023}
}

@article{ws_ecg,
  abstract  = {An electrocardiogram (ECG) records the electrical activity of the heart; it contains rich pathological information on cardiovascular diseases, such as arrhythmia. However, it is difficult to visually analyze ECG signals due to their complexity and nonlinearity. The wavelet scattering transform can generate translation-invariant and deformation-stable representations of ECG signals through cascades of wavelet convolutions with nonlinear modulus and averaging operators. We proposed a novel approach using wavelet scattering transform to automatically classify four categories of arrhythmia ECG heartbeats, namely, nonectopic (N), supraventricular ectopic (S), ventricular ectopic (V), and fusion (F) beats. In this study, the wavelet scattering transform extracted 8 time windows from each ECG heartbeat. Two dimensionality reduction methods, principal component analysis (PCA) and time window selection, were applied on the 8 time windows. These processed features were fed to the neural network (NN), probabilistic neural network (PNN), and k-nearest neighbour (KNN) classifiers for classification. The 4th time window in combination with KNN (k=4) has achieved the optimal performance with an averaged accuracy, positive predictive value, sensitivity, and specificity of 99.3%, 99.6%, 99.5%, and 98.8%, respectively, using tenfold cross-validation. Thus, our proposed model is capable of highly accurate arrhythmia classification and will provide assistance to physicians in ECG interpretation.},
  author    = {Zhishuai Liu and Guihua Yao and Qing Zhang and Junpu Zhang and Xueying Zeng},
  doi       = {10.1155/2020/3215681},
  issn      = {17486718},
  journal   = {Computational and Mathematical Methods in Medicine},
  pmid      = {33133225},
  publisher = {Hindawi Limited},
  title     = {{Wavelet Scattering Transform for ECG Beat Classification}},
  volume    = {2020},
  year      = {2020}
}

@misc{ws_audio,
  abstract = {Mel-frequency cepstral coefficients (MFCCs) are efficient audio descriptors providing spectral energy measurements over short time windows of length 23 ms. These measurements , however, lose non-stationary spectral information such as transients or time-varying structures. It is shown that this information can be recovered as spectral co-occurrence coefficients. Scattering operators compute these coefficients with a cascade of wavelet filter banks and modulus recti-fiers. The signal can be reconstructed from scattering coefficients by inverting these wavelet modulus operators. An application to genre classification shows that second-order co-occurrence coefficients improve results obtained by MFCC and Delta-MFCC descriptors. 1},
  author   = {Joakim Andén and Stéphane Mallat},
  title    = {{Multiscale Scattering for Audio Classification}},
  url      = {http://www.cmap.},
  year     = {2011}
}

@article{ws,
  abstract = {A scattering transform defines a locally translation invariant representation which is stable to time-warping deformations. It extends MFCC representations by computing modulation spectrum coefficients of multiple orders, through cascades of wavelet convolutions and modulus operators. Second-order scattering coefficients characterize transient phenomena such as attacks and amplitude modulation. A frequency transposition invariant representation is obtained by applying a scattering transform along log-frequency. State-the-of-art classification results are obtained for musical genre and phone classification on GTZAN and TIMIT databases, respectively.},
  author   = {Joakim Andén and Stéphane Mallat},
  doi      = {10.1109/TSP.2014.2326991},
  month    = {4},
  title    = {{Deep Scattering Spectrum}},
  url      = {http://arxiv.org/abs/1304.6763 http://dx.doi.org/10.1109/TSP.2014.2326991},
  year     = {2013}
}

@article{narw_cn_denoising,
  abstract  = {This paper proposes a robust system for detecting North Atlantic right whales by using deep learning methods to denoise noisy recordings. Passive acoustic recordings of right whale vocalisations are subject to noise contamination from many sources, such as shipping and offshore activities. When such data are applied to uncompensated classifiers, accuracy falls substantially. To build robustness into the detection process, two separate approaches that have proved successful for image denoising are considered. Specifically, a denoising convolutional neural network and a denoising autoencoder, each of which is applied to spectrogram representations of the noisy audio signal, are developed. Performance is improved further by matching the classifier training to include the vestigial signal that remains in clean estimates after the denoising process. Evaluations are performed first by adding white, tanker,trawler, and shot noises at signal-to-noise ratios from -10 to +5 dB to clean recordings to simulate noisy conditions. Experiments show that denoising gives substantial improvements to accuracy, particularly when using the vestigial-trained classifier. A final test applies the proposed methods to previously unseen noisy right whale recordings and finds that denoising is able to improve performance over the baseline clean-trained model in this new noise environment.},
  author    = {William Vickers and Ben Milner and Denise Risch and Robert Lee},
  doi       = {10.1121/10.0005128},
  issn      = {0001-4966},
  issue     = {6},
  journal   = {The Journal of the Acoustical Society of America},
  month     = {6},
  pages     = {3797-3812},
  pmid      = {34241455},
  publisher = {Acoustical Society of America (ASA)},
  title     = {{Robust North Atlantic right whale detection using deep learning models for denoising}},
  volume    = {149},
  year      = {2021}
}

@article{se_erbe_king,
  abstract  = {This article describes an automatic detector for marine mammal vocalizations. Even though there has been previous research on optimizing automatic detectors for specific calls or specific species, the detection of any type of call by a diversity of marine mammal species still poses quite a challenge-and one that is faced more frequently as the scope of passive acoustic monitoring studies and the amount of data collected increase. Information (Shannon) entropy measures the amount of information in a signal. A detector based on spectral entropy surpassed two commonly used detectors based on peak-energy detection. Receiver operating characteristic curves were computed for performance comparison. The entropy detector performed considerably faster than real time. It can be used as a first step in an automatic signal analysis yielding potential signals. It should be followed by automatic classification, recognition, and identification algorithms to group and identify signals. Examples are shown from underwater recordings in the Western Canadian Arctic. Calls of a variety of cetacean and pinniped species were detected. © 2008 Acoustical Society of America.},
  author    = {Christine Erbe and Andrew R. King},
  doi       = {10.1121/1.2982368},
  issn      = {0001-4966},
  issue     = {5},
  journal   = {The Journal of the Acoustical Society of America},
  month     = {11},
  pages     = {2833-2840},
  pmid      = {19045771},
  publisher = {Acoustical Society of America (ASA)},
  title     = {{Automatic detection of marine mammals using information entropy}},
  volume    = {124},
  year      = {2008}
}

@inproceedings{se_dolphin,
  abstract = {To manually detect dolphin whistle from the growing sound recordings of passive acoustic monitoring is laborious. In order to solve this problem, two dolphin whistle signal detection methods based on the spectral entropy are analyzed in this paper. The adaptive band-partitioning spectral entropy detection algorithm is improved and a mel-frequency band spectral entropy detection method is proposed for the dolphin whistle detection. The experimental results show that the detection methods could realize automatic detection and find the endpoints. The detection probability could reach more than 90% and the endpoint accuracy could reach more than 60% for both methods. The detection methods have some potential applications in biologically inspired communication based on the whistle duration or time delay modulation. A simple example is described by employing Morse code to modulate the text information into various whistle durations. Pool experiment verifies the feasibility of the Morse code based bionic communication method.},
  author   = {Gang Qiao and Tianlong Ma and Songzuo Liu and Naihua Zheng and Zeeshan Babar and Yanling Yin},
  doi      = {10.1109/OCEANSE.2019.8866876},
  journal  = {OCEANS 2019 - Marseille, OCEANS Marseille 2019},
  title    = {{Spectral Entropy Based Dolphin Whistle Detection Algorithm and Its Possible Application for Biologically Inspired Communication}},
  volume   = {2019-June},
  year     = {2019}
}

@article{blue_fin_detection,
  abstract  = {The growing availability of long-term and large-scale passive acoustic recordings open the possibility of monitoring the vocal activity of elusive oceanic species, such as fin whales (Balaenoptera physalus), in order to acquire knowledge on their distribution, behavior, population structure and abundance. Fin whales produce low-frequency and high-intensity pulses, both as single vocalizations and as song sequences (only males) which can be detected over large distances. Numerous distant fin whales producing these pulses generate a so-called chorus, by spectrally and temporally overlapping single vocalizations. Both fin whale pulses and fin whale chorus provide a distinct source of information on fin whales present at different distances to the recording location. The manual review of vast amounts of passive acoustic data for the presence of single vocalizations and chorus by human experts is, however, time-consuming, often suffers from low reproducibility and in its entirety, it is practically impossible. In this publication, we present and compare robust algorithms for the automatic detection of fin whale choruses and pulses which yield good performance results (i.e., false positive rates < 3% and true positive rates > 76%) when applied to real-world passive acoustic datasets characterized by vast amounts of data, with only a small proportion of the data containing the target sounds, and diverse soundscapes from the Southern Ocean.},
  author    = {Elena Schall and Clea Parcerisas},
  doi       = {10.3390/jmse10121831},
  issn      = {20771312},
  issue     = {12},
  journal   = {Journal of Marine Science and Engineering},
  keywords  = {20 Hz pulse,Balaenoptera physalus,automatic detection,chorus,fin whale,kurtosis},
  month     = {12},
  publisher = {MDPI},
  title     = {{A Robust Method to Automatically Detect Fin Whale Acoustic Presence in Large and Diverse Passive Acoustic Datasets}},
  volume    = {10},
  year      = {2022}
}

@article{dmd_hmm,
  abstract  = {The negative effects of human activities within the ecological space of whales remains an issue of concern to marine ecologists. The accurate detection and subsequent classification of whale species are vital in mitigating these negative effects. Automatic detection techniques have come in handy for the efficient detection of the various whale species without human error. Hidden Markov model (HMM) remains one the most efficient detectors of whale species. However, its performance efficiency is greatly influenced by the feature vectors adapted with it. In this work, we propose the use of the kernel dynamic mode decomposition (kDMD) algorithm as a tool to extract features of baleen whale species, which are then adapted with HMM for their detection. Dynamic mode decomposition (DMD) is an eigendecomposition-based algorithm that is capable of extracting latent underlying features of non-linear signals such as those vocalised by whales. However, the underlying cost of DMD is the singular value decomposition (SVD), which adds significant complexity to the modes derivation steps. Thus, this work is introducing the kernel method into the DMD, in order to find a more efficient way of computing DMD without explicitly using the SVD algorithm. Furthermore, the feature formation steps in the original DMD was modified (mDMD) in this work, to make it more generic for datasets with sparse whale sound samples. The performance of the detectors was tested on datasets containing sounds of southern right whales (SRWs) and humpback whales. The results obtained show a high true positive rate (TPR), high precision (PREC) and low error rate (ERR) for both species. The performance of the three DMD-based feature-extraction methods were compared. The kDMD-HMM generally performed better than the mDMD-HMM and DMD-HMM detectors. The methods proposed here can be tailored for the automatic detection and classification of other vocalising animal species through their sounds.},
  author    = {A. M. Usman and D. J.J. Versfeld},
  doi       = {10.1016/j.ecoinf.2022.101766},
  issn      = {15749541},
  journal   = {Ecological Informatics},
  keywords  = {Baleen whales,DMD,Detection,Eigendecomposition,Error rate,Feature extraction,HMM,Kernel DMD,Precision,True positive rate},
  month     = {11},
  publisher = {Elsevier B.V.},
  title     = {{Detection of baleen whale species using kernel dynamic mode decomposition-based feature extraction with a hidden Markov model}},
  volume    = {71},
  year      = {2022}
}

@article{ecg_ws_svm,
  abstract  = {Cardiovascular disease detection and its prevention are among the most demanding tasks in the healthcare system nowadays, as around 50 million people worldwide are at risk of being affected by heart disease. The heart's electrical activity recorded by an electrocardiogram (ECG) provides vital pathological information about cardiac abnormalities such as arrhythmia. However, the complexity and non-linearity observed in ECG signals make disease anticipation difficult. In this work, we proposed a new approach to classify 17-classes of cardiac arrhythmia using wavelet scattering transform (WST). The WST can provide translation-invariant and deformation-stable representations of ECG by using a series of wavelet convolutions with non-linear modulus and averaging operators. Scattering coefficients from four-time windows of WST for fixed-duration ECG fragments are taken as input features to the SVM classifier. We achieved an overall classification accuracy of 98.90% in categorizing 17 arrhythmia classes taken from the MIT-BIH arrhythmia database, having 1000 ECG fragments of 45 subjects. The proposed method categorizes a 10-second ECG fragment with an average classification time of 0.007 s on a computing platform of a 2.5 GHz processor with 8 GB RAM. Our results outperform existing state-of-the-art solutions and can be deployed in real-world applications.},
  author    = {Sudestna Nahak and Akanksha Pathak and Goutam Saha},
  doi       = {10.1016/j.eswa.2023.120019},
  issn      = {09574174},
  journal   = {Expert Systems with Applications},
  keywords  = {Arrhythmia,ECG,Fragment-level,SVM,Wavelet scattering transform},
  month     = {8},
  publisher = {Elsevier Ltd},
  title     = {{Fragment-level classification of ECG arrhythmia using wavelet scattering transform}},
  volume    = {224},
  year      = {2023}
}

@article{ws_fault_diag,
  abstract  = {Analog circuits are a critical part of industrial electronics and systems. Estimates in the literature show that, even though analog circuits comprise less than 20% of all circuits, they are responsible for more than 80% of faults. Hence, analog circuit fault diagnosis and isolation can be a valuable means of ensuring the reliability of circuits. This paper introduces a novel technique of learning time–frequency representations, using learnable wavelet scattering networks, for the fault diagnosis of circuits and rotating machinery. Wavelet scattering networks, which are fixed time– frequency representations based on existing wavelets, are modified to be learnable so that they can learn features that are optimal for fault diagnosis. The learnable wavelet scattering networks are developed using the genetic algorithm-based optimization of second-generation wavelet transform operators. The simulation and experimental results for the diagnosis of analog circuit faults demon-strates that the developed diagnosis scheme achieves greater fault diagnosis accuracy than other methods in the literature, even while considering a larger number of fault classes. The performance of the diagnosis scheme on benchmark datasets of bearing faults and gear faults shows that the developed method generalizes well to fault diagnosis in multiple domains and has good transfer learning performance, too.},
  author    = {Varun Khemani and Michael H. Azarian and Michael G. Pecht},
  doi       = {10.3390/electronics11030451},
  issn      = {20799292},
  issue     = {3},
  journal   = {Electronics (Switzerland)},
  keywords  = {Analog circuits,Fault diagnosis,Fault isolation,Rotating machinery,Scattering networks,Second-generation wavelet transform,Wavelet scattering networks},
  month     = {2},
  publisher = {MDPI},
  title     = {{Learnable Wavelet Scattering Networks: Applications to Fault Diagnosis of Analog Circuits and Rotating Machinery}},
  volume    = {11},
  year      = {2022}
}

@article{ws_speech,
  abstract  = {In recent years, developing robust systems for automatic detection of pathological speech has attracted increasing interest among researchers and clinicians. This study proposes an end-to-end approach based on wavelet scattering network (WSN) for detection of pathological speech. In the proposed approach, the WSN (which involves no learning) extracts suitable information from the input raw speech signal and this information is then passed through a multi-layer perceptron (MLP) in order to classify the speech signal as either healthy or pathological. The results show that the proposed approach outperformed a convolutional neural network (CNN) based end-to-end system in distinguishing pathological speech from healthy speech. Furthermore, the proposed system achieved comparable performance with a state-of-the-art traditional system based on hand-crafted features for uncompressed speech, but gave better performance than the traditional system for compressed speech of low bit rates.},
  author    = {Mittapalle Kiran Reddy and Yagnavajjula Madhu Keerthana and Paavo Alku},
  doi       = {10.1109/LSP.2022.3199669},
  issn      = {15582361},
  journal   = {IEEE Signal Processing Letters},
  keywords  = {CNN,Convolutional neural networks,Feature extraction,MP3 compression,Pathology,Scattering,Task analysis,Wavelet scattering network,Wavelet transforms,Wireless sensor networks,openSMILE features,pathological speech},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {{End-to-end Pathological Speech Detection using Wavelet Scattering Network}},
  year      = {2022}
}

@article{ws_audio2,
  abstract  = {This paper proposes a new approach to recognize environmental sounds for audio surveillance and security applications. The sounds are extremely versatile, including sounds generated in domestic, business, and outdoor environments. Since this variability is hard to model, investigations concentrate mostly on specific classes of sounds. Among those, the system that is able to recognize indoor environmental sounds may be of great importance for surveillance and security applications. These functionalities can also be used in portable teleassistive devices to inform disabled and elderly persons affected in their hearing capabilities about specific environmental sounds (door bells, alarm signals, etc.). We propose to apply an environmental sounds classification method, based on scattering transform and the principal component analysis (PCA). Our method integrates ability of PCA to de-correlate the coefficients by extracting a linear relationship with what of scatter transform analysis to derive feature vectors used for environmental sounds classification. The performance evaluation shows the superiority of this novel sound recognition method. The support vector machines method based on Gaussian kernel is used to classify the datasets due to its capability to deal with high-dimensional data. Our SVM−based multiclass classification approach seems well suited for real-world recognition tasks. Experimental results have revealed the good performance of the proposed system and the classification accuracy is up to 92.22%.},
  author    = {Sameh Souli and Zied Lachiri},
  doi       = {10.1016/j.apacoust.2017.08.002},
  issn      = {1872910X},
  journal   = {Applied Acoustics},
  keywords  = {Audio sounds,Classification,MFCCs,SVM multiclass,Scattering transform},
  month     = {1},
  pages     = {270-282},
  publisher = {Elsevier Ltd},
  title     = {{Audio sounds classification using scattering features and support vectors machines for medical surveillance}},
  volume    = {130},
  year      = {2018}
}

@article{blue_whale,
  abstract  = {Antarctic blue whales (Balaenoptera musculus intermedia) are the largest and formerly most abundant blue whale subspecies, but were hunted to near extinction last century. Estimated whaling mortality was unsustainable from 1928 to 1972 (except during 1942-1944), depleting them from 239,000 (95% interval 202,000-311,000) to a low of 360 (150-840) in 1973. Obtaining statistical evidence for subsequent increases has proved difficult due to their scarcity. We fitted Bayesian models to three sighting series (1968-2001), constraining maximum rates of increase to 12% per annum. These models indicated that Antarctic blue whales are increasing at a mean rate of 7.3% per annum (1.4%-11.6%). Informative priors based on blue whale biology (4.3%, SD = 1.9%) and a Bayesian hierarchical meta-analysis of increase rates in other blue whale populations (-0.3%, SD = 11.6%), suggest plausible increase rates are lower (although the latter has wide intervals), but a meta-analysis of other mysticetes obtains similar rates of increase (6.7%, SD = 4.0%). Possible biases affecting the input abundance estimates are discussed. Although Antarctic blue whales appear to have been increasing since Soviet illegal whaling ended in 1972, they still need to be protected - their estimated 1996 population size, 1,700 (860-2,900), was just 0.7% (03%-1.3%) of the pre-exploitation level.},
  author    = {Trevor A. Branch and Koji Matsuoka and Tomio Miyashita},
  doi       = {10.1111/j.1748-7692.2004.tb01190.x},
  issn      = {08240469},
  issue     = {4},
  journal   = {Marine Mammal Science},
  keywords  = {Abundance estimate,Antarctic blue whales,Balaenoptera musculus brevicauda,Balaenoptera musculus intermedia,Bayesian models,Meta-analysis,Population assessment,Rate of increase,Southern Hemisphere,True blue whales},
  pages     = {726-754},
  publisher = {Society for Marine Mammology},
  title     = {{Evidence for increases in Antarctic blue whales based on Bayesian modelling}},
  volume    = {20},
  year      = {2004}
}

@article{fin_whale,
  abstract  = {The fin whale is listed as globally vulnerable, with ongoing threats to their population, yet little is known about the distribution and movements of the Southern Hemisphere sub-species, Balaenoptera physalus quoyi. This study assesses fin whale distribution in the Southern Hemisphere analysing acoustic recordings from 15 locations in Antarctic and Australian waters from 2002 to 2019. A seasonal acoustic presence of fin whales in Antarctic waters from late austral summer to autumn (February to June) with long-term, consistent annual usage areas was identified at the Southern Kerguelen Plateau and Dumont d’Urville sites. In comparison, limited vocal presence of fin whales was observed at the Casey site. In Australian waters, fin whales were seasonally present from austral autumn to mid-spring (May to October) on east and west coasts, with a decadal pattern of acoustic presence observed at Cape Leeuwin, WA. Two migratory pathways are identified, from the Indian sector of Antarctica to the west coast of Australia and from the Pacific sector of Antarctica to the east coast of Australia. The identified seasonal distributions and migratory pathways provide valuable information to aid in monitoring the recovery of this vulnerable sub-species. We suggest the identified distribution and dispersal from the Southern Kerguelen Plateau and Dumont d’Urville sites to the west and east coasts of Australia respectively, as well as the spatial separation between Antarctic sites, provide preliminary evidence of separate sub-populations of the Southern Hemisphere sub-species of fin whale.},
  author    = {Meghan G. Aulich and Robert D. McCauley and Brian S. Miller and Flore Samaran and Giacomo Giorli and Benjamin J. Saunders and Christine Erbe},
  doi       = {10.3389/fmars.2022.864153},
  issn      = {22967745},
  journal   = {Frontiers in Marine Science},
  keywords  = {Antarctica,Australia,Balaenoptera physalus,fin whale,migratory pathway,passive acoustic monitoring,seasonal distribution},
  month     = {5},
  publisher = {Frontiers Media S.A.},
  title     = {{Seasonal Distribution of the Fin Whale (Balaenoptera physalus) in Antarctic and Australian Waters Based on Passive Acoustics}},
  volume    = {9},
  year      = {2022}
}

@article{sorp_sohn,
  title   = {{Towards collective circum-Antarctic passive acoustic monitoring: The Southern Ocean hydrophone network (SOHN)}},
  author  = {Van Opzeeland, Ilse and Samaran, Flore and Stafford, Kathleen M and Findlay, Ken and Gedamke, Jason and Harris, Danielle and Miller, Brian S},
  journal = {Polarforschung},
  volume  = {83},
  number  = {2},
  pages   = {47--61},
  year    = {2014}
}

@article{ws_joint_tf,
  abstract = {We introduce the joint time-frequency scattering transform, a time shift invariant descriptor of time-frequency structure for audio classification. It is obtained by applying a two-dimensional wavelet transform in time and log-frequency to a time-frequency wavelet scalogram. We show that this descriptor successfully characterizes complex time-frequency phenomena such as time-varying filters and frequency modulated excitations. State-of-the-art results are achieved for signal reconstruction and phone segment classification on the TIMIT dataset.},
  author   = {Joakim Andén and Vincent Lostanlen and Stéphane Mallat},
  doi      = {10.1109/MLSP.2015.7324385},
  month    = {12},
  title    = {{Joint Time-Frequency Scattering for Audio Classification}},
  url      = {http://arxiv.org/abs/1512.02125 http://dx.doi.org/10.1109/MLSP.2015.7324385},
  year     = {2015}
}

@article{cnn_fin_whale,
  author  = {M. Román Ruiz and C. Rossi and J.A. Esteban},
  doi     = {10.1016/j.ecoinf.2023.102243},
  issn    = {15749541},
  journal = {Ecological Informatics},
  month   = {11},
  pages   = {102243},
  title   = {{Fin whale pulse detection with deep neural networks}},
  volume  = {77},
  url     = {https://linkinghub.elsevier.com/retrieve/pii/S1574954123002728},
  year    = {2023}
}

@article{chi2_fs,
  title     = {{Intrusion detection model using fusion of chi-square feature selection and multi class SVM}},
  author    = {Thaseen, Ikram Sumaiya and Kumar, Cherukuri Aswani},
  journal   = {{Journal of King Saud University-Computer and Information Sciences}},
  volume    = {29},
  number    = {4},
  pages     = {462--472},
  year      = {2017},
  publisher = {Elsevier}
}

@inproceedings{origkmeans,
  title        = {Some methods for classification and analysis of multivariate observations},
  author       = {MacQueen, James and others},
  booktitle    = {Proceedings of the fifth Berkeley symposium on mathematical statistics and probability},
  volume       = {1},
  number       = {14},
  pages        = {281--297},
  year         = {1967},
  organization = {Oakland, CA, USA}
}


% paper 3

@book{waveletsandsubbandcoding,
  title     = {Wavelets and Subband Coding},
  author    = {Kovacevic, J. and Vetterli, M.},
  isbn      = {9780130970800},
  lccn      = {95005967},
  series    = {Prentice-Hall signal processing series},
  url       = {https://books.google.co.za/books?id=4Qt_QgAACAAJ},
  year      = {1995},
  publisher = {Prentice Hall PTR}
}

@article{kymatio,
  author  = {Mathieu Andreux and Tomás Angles and Georgios Exarchakis and Roberto Leonarduzzi and Gaspar Rochette and Louis Thiry and John Zarka and Stéphane Mallat and Joakim Andén and Eugene Belilovsky and Joan Bruna and Vincent Lostanlen and Muawiz Chaudhary and Matthew J. Hirn and Edouard Oyallon and Sixin Zhang and Carmine Cella and Michael Eickenberg},
  title   = {Kymatio: Scattering Transforms in Python},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {60},
  pages   = {1--6},
  url     = {http://jmlr.org/papers/v21/19-047.html}
}

@article{2dscattering,
  title     = {Invariant scattering convolution networks},
  author    = {Bruna, Joan and Mallat, St{\'e}phane},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  volume    = {35},
  number    = {8},
  pages     = {1872--1886},
  year      = {2013},
  publisher = {IEEE}
}

@article{sklearn,
  title   = {Scikit-learn: Machine Learning in {P}ython},
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
             and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
             and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
             Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2825--2830},
  year    = {2011}
}

@article{medmnist,
  title     = {MedMNIST v2-A large-scale lightweight benchmark for 2D and 3D biomedical image classification},
  author    = {Yang, Jiancheng and Shi, Rui and Wei, Donglai and Liu, Zequan and Zhao, Lin and Ke, Bilian and Pfister, Hanspeter and Ni, Bingbing},
  journal   = {Scientific Data},
  volume    = {10},
  number    = {1},
  pages     = {41},
  year      = {2023},
  publisher = {Nature Publishing Group UK London}
}

@incollection{pytorch,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  pages     = {8024--8035},
  year      = {2019},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{1dscattering1,
  title        = {Multiscale Scattering for Audio Classification.},
  author       = {And{\'e}n, Joakim and Mallat, St{\'e}phane},
  booktitle    = {ISMIR},
  pages        = {657--662},
  year         = {2011},
  organization = {Miami, Florida}
}

@article{3dscattering,
  abstract  = {Recent research has shown that utilizing the spectral-spatial information can improve the performance of hyperspectral image (HSI) classification. Since HSI is a 3-D cube datum, 3-D spatial filtering becomes a simple and effective method for extracting the spectral-spatial information. In this paper, we propose a 3-D scattering wavelet transform, which filters the HSI cube data with a cascade of wavelet decompositions, complex modulus, and local weighted averaging. The scattering feature can adequately capture the spectral-spatial information for classification. In the classification step, a support vector machine based on Gaussian kernel is used as a classifier due to its capability to deal with high-dimensional data. Our method is fully evaluated on four classic HSIs, i.e., Indian Pines, Pavia University, Botswana, and Kennedy Space Center. The classification results show that our method achieves as high as 94.46 \%, 99.30 \%, 97.57 \%, and 95.20 \% accuracies, respectively, when only 5 \% of the total samples per class is labeled.},
  author    = {Yuan Yan Tang and Yang Lu and Haoliang Yuan},
  doi       = {10.1109/TGRS.2014.2360672},
  issn      = {01962892},
  issue     = {5},
  journal   = {IEEE Transactions on Geoscience and Remote Sensing},
  keywords  = {3-D scattering wavelet transform,3-D spatial filtering,Classification,hyperspectral image (HSI),spectral-spatial},
  month     = {5},
  pages     = {2467-2480},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {Hyperspectral image classification based on three-dimensional scattering wavelet transform},
  volume    = {53},
  year      = {2015}
}

@inproceedings{harmonicscattering,
  author    = {Eickenberg, Michael and Exarchakis, Georgios and Hirn, Matthew and Mallat, Stephane},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Solid Harmonic Wavelet Scattering: Predicting Quantum Molecular Energy from Invariant Descriptors of 3D  Electronic Densities},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/72b386224056bf940cd5b01341f65e9d-Paper.pdf},
  volume    = {30},
  year      = {2017}
}

@article{jointtfscattering1,
  abstract = {We introduce the joint time-frequency scattering transform, a time shift invariant descriptor of time-frequency structure for audio classification. It is obtained by applying a two-dimensional wavelet transform in time and log-frequency to a time-frequency wavelet scalogram. We show that this descriptor successfully characterizes complex time-frequency phenomena such as time-varying filters and frequency modulated excitations. State-of-the-art results are achieved for signal reconstruction and phone segment classification on the TIMIT dataset.},
  author   = {Joakim Andén and Vincent Lostanlen and Stéphane Mallat},
  doi      = {10.1109/MLSP.2015.7324385},
  month    = {12},
  title    = {Joint Time-Frequency Scattering for Audio Classification},
  url      = {http://arxiv.org/abs/1512.02125 http://dx.doi.org/10.1109/MLSP.2015.7324385},
  year     = {2015}
}

@article{jointtfscattering2,
  abstract = {In time series classification and regression, signals are typically mapped into some intermediate representation used for constructing models. Since the underlying task is often insensitive to time shifts, these representations are required to be time-shift invariant. We introduce the joint time-frequency scattering transform, a time-shift invariant representation which characterizes the multiscale energy distribution of a signal in time and frequency. It is computed through wavelet convolutions and modulus non-linearities and may therefore be implemented as a deep convolutional neural network whose filters are not learned but calculated from wavelets. We consider the progression from mel-spectrograms to time scattering and joint time-frequency scattering transforms, illustrating the relationship between increased discriminability and refinements of convolutional network architectures. The suitability of the joint time-frequency scattering transform for time-shift invariant characterization of time series is demonstrated through applications to chirp signals and audio synthesis experiments. The proposed transform also obtains state-of-the-art results on several audio classification tasks, outperforming time scattering transforms and achieving accuracies comparable to those of fully learned networks.},
  author   = {Joakim Andén and Vincent Lostanlen and Stéphane Mallat},
  doi      = {10.1109/TSP.2019.2918992},
  month    = {7},
  title    = {Joint Time-Frequency Scattering},
  url      = {http://arxiv.org/abs/1807.08869 http://dx.doi.org/10.1109/TSP.2019.2918992},
  year     = {2018}
}


@article{1dscattering2,
  title     = {Deep scattering spectrum},
  author    = {And{\'e}n, Joakim and Mallat, St{\'e}phane},
  journal   = {IEEE Transactions on Signal Processing},
  volume    = {62},
  number    = {16},
  pages     = {4114--4128},
  year      = {2014},
  publisher = {IEEE}
}

@article{groupinvariantscattering,
  title     = {Group invariant scattering},
  author    = {Mallat, St{\'e}phane},
  journal   = {Communications on Pure and Applied Mathematics},
  volume    = {65},
  number    = {10},
  pages     = {1331--1398},
  year      = {2012},
  publisher = {Wiley Online Library}
}

@misc{MATLAB,
  year      = {2022},
  author    = {{MathWorks Inc.}},
  title     = {{MATLAB Wavelet Toolbox (R2024a)}},
  publisher = {{MathWorks Inc.}},
  address   = {Natick, Massachusetts, United States},
  url       = {https://www.mathworks.com/help/wavelet/}
}

@article{learnablewavelettransform,
  abstract  = {High-frequency (HF) signals are ubiquitous in the industrial world and are of great use for monitoring of industrial assets. Most deep-learning tools are designed for inputs of fixed and/or very limited size and many successful applications of deep learning to the industrial context use as inputs extracted features, which are a manually and often arduously obtained compact representation of the original signal. In this paper, we propose a fully unsupervised deep-learning framework that is able to extract a meaningful and sparse representation of raw HF signals. We embed in our architecture important properties of the fast discrete wavelet transform (FDWT) such as 1) the cascade algorithm; 2) the conjugate quadrature filter property that links together the wavelet, the scaling, and transposed filter functions; and 3) the coefficient denoising. Using deep learning, we make this architecture fully learnable: Both the wavelet bases and the wavelet coefficient denoising become learnable. To achieve this objective, we propose an activation function that performs a learnable hard thresholding of the wavelet coefficients. With our framework, the denoising FDWT becomes a fully learnable unsupervised tool that does not require any type of pre- or postprocessing or any prior knowledge on wavelet transform. We demonstrate the benefits of embedding all these properties on three machine-learning tasks performed on open-source sound datasets. We perform an ablation study of the impact of each property on the performance of the architecture, achieve results well above baseline, and outperform other state-of-the-art methods.},
  author    = {Gabriel Michau and Gaetan Frusque and Olga Fink},
  doi       = {10.1073/pnas.2106598119},
  issn      = {10916490},
  issue     = {8},
  journal   = {Proceedings of the National Academy of Sciences of the United States of America},
  keywords  = {Deep learning,Fast discrete wavelet decomposition,High-frequency signals,Sparse decomposition,Unsupervised anomaly detection},
  month     = {2},
  pmid      = {35181603},
  publisher = {National Academy of Sciences},
  title     = {Fully learnable deep wavelet transform for unsupervised monitoring of high-frequency time series},
  volume    = {119},
  year      = {2022}
}

@inproceedings{sincnet,
  title        = {Speaker recognition from raw waveform with sincnet},
  author       = {Ravanelli, Mirco and Bengio, Yoshua},
  booktitle    = {2018 IEEE spoken language technology workshop (SLT)},
  pages        = {1021--1028},
  year         = {2018},
  organization = {IEEE}
}

@misc{mnist,
  title     = {MNIST handwritten digit database},
  author    = {LeCun, Yann and Cortes, Corinna and Burges, Chris and others},
  year      = {2010},
  publisher = {Florham Park, NJ, USA}
}

@article{lda,
  author   = {Fisher, R. A.},
  title    = {THE USE OF MULTIPLE MEASUREMENTS IN TAXONOMIC PROBLEMS},
  journal  = {Annals of Eugenics},
  volume   = {7},
  number   = {2},
  pages    = {179-188},
  doi      = {https://doi.org/10.1111/j.1469-1809.1936.tb02137.x},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-1809.1936.tb02137.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x},
  abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
  year     = {1936}
}





@misc{adam,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = {2017},
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{separablecnn,
  title     = {Efficient convolution neural networks for object tracking using separable convolution and filter pruning},
  author    = {Mao, Yuanhong and He, Zhanzhuang and Ma, Zhong and Tang, Xuehan and Wang, Zhuping},
  journal   = {IEEE Access},
  volume    = {7},
  pages     = {106466--106474},
  year      = {2019},
  publisher = {IEEE}
}

@misc{batchnorm,
  title         = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author        = {Sergey Ioffe and Christian Szegedy},
  year          = {2015},
  eprint        = {1502.03167},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{relu,
  title         = {Deep Learning using Rectified Linear Units (ReLU)},
  author        = {Abien Fred Agarap},
  year          = {2019},
  eprint        = {1803.08375},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}